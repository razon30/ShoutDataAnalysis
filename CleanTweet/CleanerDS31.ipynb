{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a9962a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3fc5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_stem = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "pt_stem = PorterStemmer()\n",
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482a39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleaner as Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f497c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = '/Volumes/Works/Development/Python/Shout/newTweets/DS2/tweet31.xlsx'\n",
    "text = 'Text'\n",
    "loc = 'Location'\n",
    "date = 'date'\n",
    "cData = 'cleanedData'\n",
    "canNotConvert = 'cannot convert'\n",
    "convert = 'convert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d32e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['date', 'Text', 'Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a980de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(filePath, header = None, names = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88cf2013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369318"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "839f933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTheExcel():\n",
    "    filePath1 = '/Volumes/Works/Development/Python/Shout/newTweets/DS2/Cleanedtweet31.xlsx'\n",
    "    df.to_excel(filePath1, index = False)\n",
    "    print(\"Saved the File\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ce5658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskModel(existingText, newText):\n",
    "    mask = df.label == existingText\n",
    "    df.label[mask] = newText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d020dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = WordPunctTokenizer()\n",
    "pattern1 = r'@[A-Za-z0-9]+'\n",
    "pattern2 = r'https?://[A-Za-z0-9./]+'\n",
    "combinedPattern = r'|'.join((pattern1, pattern2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7cf1d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = []\n",
    "\n",
    "appose = []\n",
    "columnapostrophes = 'apostrophes'\n",
    "\n",
    "aplhaneu = []\n",
    "columnalphanumeric = 'alphanumeric'\n",
    "\n",
    "url = []\n",
    "columnURL = 'URL'\n",
    "\n",
    "htmlXml = []\n",
    "columnhtmlXml = 'htmlXml'\n",
    "\n",
    "tokenize = []\n",
    "columntokenize = 'Tokenize'\n",
    "\n",
    "hashtagMention = []\n",
    "columnhashtagMention = 'hashtagMention'\n",
    "\n",
    "singleLetter = []\n",
    "columnsingleLetter = 'SingleLetter'\n",
    "\n",
    "repeateCharacter = []\n",
    "columnrepeateCharacter = 'repeateCharacter'\n",
    "\n",
    "puctuation = []\n",
    "columnpuctuation = 'puctuation'\n",
    "\n",
    "keywords = []\n",
    "columnKeywords = 'Keywords'\n",
    "\n",
    "stopWords = []\n",
    "columnStropWords = 'StropWords'\n",
    "\n",
    "lemmatize = []\n",
    "columnlemmatize = 'lemmatize'\n",
    "\n",
    "shortWord = []\n",
    "columnShortWords = 'ShortWords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b97d5372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Just out of a meeting where one cat got chased through the cat flap and then proceeded to rip a chair to pieces, while the other lay snoring (loudly) by the fire. #workfromhomelife'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = df.Text[:]\n",
    "testing[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27f14263",
   "metadata": {},
   "outputs": [],
   "source": [
    "testResult = []\n",
    "for t in testing:\n",
    "    t = str(t)\n",
    "    #print(\"Before: \"+str(t))\n",
    "     #removing markup\n",
    "    if t == None or len(str(t)) == 0:\n",
    "        t = convert\n",
    "    cleanded = tweetCleaner(t)\n",
    "    #print(\"After: \"+cleanded)\n",
    "    testResult.append(cleanded)\n",
    "    #print(\"=================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5af12acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes one related meeting being home body felt really homesick fear death knowing leaving daughter unprotected say trust higher self guiding guess child understand'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testResult[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9695ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cData] = testResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13d3754f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meeting one cat got chased cat flap proceeded rip chair piece lay snoring loudly fire workfromhomelife'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cData][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbc84a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the File\n"
     ]
    }
   ],
   "source": [
    "saveTheExcel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c70dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf52b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetCleaner(text):\n",
    "    \n",
    "# =============================================================================\n",
    "#      #removing markup\n",
    "#     if text == None or len(text) == 0:\n",
    "#         text = convert\n",
    "# =============================================================================\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = Cleaner.appos_look_up(text)\n",
    "    appose.append(text)\n",
    "    \n",
    "    text = Cleaner.remove_alphanumerics(text)\n",
    "    aplhaneu.append(text)\n",
    "    \n",
    "    text = Cleaner.remove_url(text)\n",
    "    url.append(text)\n",
    "  \n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    \n",
    "    #removing '@' and HTTPs URL\n",
    "    stripped = re.sub(combinedPattern, '', souped)\n",
    "    \n",
    "    #removing UTF-8 Bom text\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"\")\n",
    "    except :\n",
    "        clean = stripped\n",
    "        \n",
    "    htmlXml.append(clean)\n",
    "    \n",
    "    #removing hashtag and numbers\n",
    "    lettersOnly = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    hashtagMention.append(lettersOnly)\n",
    "    \n",
    "    #tokenization and removing extra white spaces\n",
    "    words = tok.tokenize(lettersOnly)\n",
    "    tokenize.append(words)\n",
    "    \n",
    "    weightedValue = Cleaner.weightCalculator(words)\n",
    "    weight.append(weightedValue)\n",
    "    \n",
    "    cleanedSentence = (\" \".join(words)).strip()\n",
    "    \n",
    "    cleanedSentence = Cleaner.remove_single_char_word(cleanedSentence)\n",
    "    singleLetter.append(cleanedSentence)\n",
    "    \n",
    "    cleanedSentence = Cleaner.remove_repeated_characters(cleanedSentence)\n",
    "    repeateCharacter.append(cleanedSentence)\n",
    "    \n",
    "    cleanedSentence = Cleaner.remove_punctuations(cleanedSentence)\n",
    "    puctuation.append(cleanedSentence)\n",
    "    \n",
    "    cleanedSentence = Cleaner.remove_extra_space(cleanedSentence)\n",
    "    #appose.append(clean)\n",
    "    \n",
    "    #cleanedSentence = Cleaner.remove_stop_words(cleanedSentence)\n",
    "    \n",
    "    cleanedSentence = Cleaner.remove_key_words(cleanedSentence)\n",
    "    keywords.append(cleanedSentence)\n",
    "    \n",
    "    cleanedSentence = Cleaner.removeStopWords(cleanedSentence)\n",
    "    stopWords.append(cleanedSentence)\n",
    "    \n",
    "    cleanedSentence = Cleaner.lemmatize_text(cleanedSentence)\n",
    "    lemmatize.append(cleanedSentence)\n",
    "    \n",
    "    cleanedSentence = Cleaner.removeShortWords(cleanedSentence)\n",
    "    shortWord.append(cleanedSentence)\n",
    "    \n",
    "    \n",
    "    return cleanedSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b833663a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Text\n",
       "1       0\n",
       "2       1\n",
       "3       2\n",
       "4       3\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()[text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b072e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
