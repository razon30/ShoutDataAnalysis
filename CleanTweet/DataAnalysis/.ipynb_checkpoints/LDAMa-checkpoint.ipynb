{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f506f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import tempfile\n",
    "import xml.etree.ElementTree as et\n",
    "import zipfile\n",
    "from itertools import chain\n",
    "\n",
    "import numpy\n",
    "from smart_open import open\n",
    "\n",
    "from gensim import utils, matutils\n",
    "from gensim.models import basemodel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.utils import check_output, revdict\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec45332",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LdaMallet(utils.SaveLoad, basemodel.BaseTopicModel):\n",
    "    \"\"\"Python wrapper for LDA using `MALLET <http://mallet.cs.umass.edu/>`_.\n",
    "\n",
    "    Communication between MALLET and Python takes place by passing around data files on disk\n",
    "    and calling Java with subprocess.call().\n",
    "\n",
    "    Warnings\n",
    "    --------\n",
    "    This is **only** python wrapper for `MALLET LDA <http://mallet.cs.umass.edu/>`_,\n",
    "    you need to install original implementation first and pass the path to binary to ``mallet_path``.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, mallet_path, corpus=None, num_topics=100, alpha=50, id2word=None, workers=4, prefix=None,\n",
    "                 optimize_interval=0, iterations=1000, topic_threshold=0.0, random_seed=0):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mallet_path : str\n",
    "            Path to the mallet binary, e.g. `/home/username/mallet-2.0.7/bin/mallet`.\n",
    "        corpus : iterable of iterable of (int, int), optional\n",
    "            Collection of texts in BoW format.\n",
    "        num_topics : int, optional\n",
    "            Number of topics.\n",
    "        alpha : int, optional\n",
    "            Alpha parameter of LDA.\n",
    "        id2word : :class:`~gensim.corpora.dictionary.Dictionary`, optional\n",
    "            Mapping between tokens ids and words from corpus, if not specified - will be inferred from `corpus`.\n",
    "        workers : int, optional\n",
    "            Number of threads that will be used for training.\n",
    "        prefix : str, optional\n",
    "            Prefix for produced temporary files.\n",
    "        optimize_interval : int, optional\n",
    "            Optimize hyperparameters every `optimize_interval` iterations\n",
    "            (sometimes leads to Java exception 0 to switch off hyperparameter optimization).\n",
    "        iterations : int, optional\n",
    "            Number of training iterations.\n",
    "        topic_threshold : float, optional\n",
    "            Threshold of the probability above which we consider a topic.\n",
    "        random_seed: int, optional\n",
    "            Random seed to ensure consistent results, if 0 - use system clock.\n",
    "\n",
    "        \"\"\"\n",
    "        self.mallet_path = mallet_path\n",
    "        self.id2word = id2word\n",
    "        if self.id2word is None:\n",
    "            logger.warning(\"no word id mapping provided; initializing from corpus, assuming identity\")\n",
    "            self.id2word = utils.dict_from_corpus(corpus)\n",
    "            self.num_terms = len(self.id2word)\n",
    "        else:\n",
    "            self.num_terms = 0 if not self.id2word else 1 + max(self.id2word.keys())\n",
    "        if self.num_terms == 0:\n",
    "            raise ValueError(\"cannot compute LDA over an empty collection (no terms)\")\n",
    "        self.num_topics = num_topics\n",
    "        self.topic_threshold = topic_threshold\n",
    "        self.alpha = alpha\n",
    "        if prefix is None:\n",
    "            rand_prefix = hex(random.randint(0, 0xffffff))[2:] + '_'\n",
    "            prefix = os.path.join(tempfile.gettempdir(), rand_prefix)\n",
    "        self.prefix = prefix\n",
    "        self.workers = workers\n",
    "        self.optimize_interval = optimize_interval\n",
    "        self.iterations = iterations\n",
    "        self.random_seed = random_seed\n",
    "        if corpus is not None:\n",
    "            self.train(corpus)\n",
    "\n",
    "    def finferencer(self):\n",
    "        \"\"\"Get path to inferencer.mallet file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Path to inferencer.mallet file.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.prefix + 'inferencer.mallet'\n",
    "\n",
    "    def ftopickeys(self):\n",
    "        \"\"\"Get path to topic keys text file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Path to topic keys text file.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.prefix + 'topickeys.txt'\n",
    "\n",
    "    def fstate(self):\n",
    "        \"\"\"Get path to temporary file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Path to file.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.prefix + 'state.mallet.gz'\n",
    "\n",
    "    def fdoctopics(self):\n",
    "        \"\"\"Get path to document topic text file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Path to document topic text file.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.prefix + 'doctopics.txt'\n",
    "\n",
    "    def fcorpustxt(self):\n",
    "        \"\"\"Get path to corpus text file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Path to corpus text file.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.prefix + 'corpus.txt'\n",
    "\n",
    "    def fcorpusmallet(self):\n",
    "        \"\"\"Get path to corpus.mallet file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Path to corpus.mallet file.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.prefix + 'corpus.mallet'\n",
    "\n",
    "    def fwordweights(self):\n",
    "        \"\"\"Get path to word weight file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Path to word weight file.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.prefix + 'wordweights.txt'\n",
    "\n",
    "    def corpus2mallet(self, corpus, file_like):\n",
    "        \"\"\"Convert `corpus` to Mallet format and write it to `file_like` descriptor.\n",
    "\n",
    "        Format ::\n",
    "\n",
    "            document id[SPACE]label (not used)[SPACE]whitespace delimited utf8-encoded tokens[NEWLINE]\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus : iterable of iterable of (int, int)\n",
    "            Collection of texts in BoW format.\n",
    "        file_like : file-like object\n",
    "            Opened file.\n",
    "\n",
    "        \"\"\"\n",
    "        for docno, doc in enumerate(corpus):\n",
    "            if self.id2word:\n",
    "                tokens = chain.from_iterable([self.id2word[tokenid]] * int(cnt) for tokenid, cnt in doc)\n",
    "            else:\n",
    "                tokens = chain.from_iterable([str(tokenid)] * int(cnt) for tokenid, cnt in doc)\n",
    "            file_like.write(utils.to_utf8(\"%s 0 %s\\n\" % (docno, ' '.join(tokens))))\n",
    "\n",
    "    def convert_input(self, corpus, infer=False, serialize_corpus=True):\n",
    "        \"\"\"Convert corpus to Mallet format and save it to a temporary text file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus : iterable of iterable of (int, int)\n",
    "            Collection of texts in BoW format.\n",
    "        infer : bool, optional\n",
    "            ...\n",
    "        serialize_corpus : bool, optional\n",
    "            ...\n",
    "\n",
    "        \"\"\"\n",
    "        if serialize_corpus:\n",
    "            logger.info(\"serializing temporary corpus to %s\", self.fcorpustxt())\n",
    "            with open(self.fcorpustxt(), 'wb') as fout:\n",
    "                self.corpus2mallet(corpus, fout)\n",
    "\n",
    "        # convert the text file above into MALLET's internal format\n",
    "        cmd = \\\n",
    "            self.mallet_path + \\\n",
    "            \" import-file --preserve-case --keep-sequence \" \\\n",
    "            \"--remove-stopwords --token-regex \\\"\\\\S+\\\" --input %s --output %s\"\n",
    "        if infer:\n",
    "            cmd += ' --use-pipe-from ' + self.fcorpusmallet()\n",
    "            cmd = cmd % (self.fcorpustxt(), self.fcorpusmallet() + '.infer')\n",
    "        else:\n",
    "            cmd = cmd % (self.fcorpustxt(), self.fcorpusmallet())\n",
    "        logger.info(\"converting temporary corpus to MALLET format with %s\", cmd)\n",
    "        check_output(args=cmd, shell=True)\n",
    "\n",
    "    def train(self, corpus):\n",
    "        \"\"\"Train Mallet LDA.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus : iterable of iterable of (int, int)\n",
    "            Corpus in BoW format\n",
    "\n",
    "        \"\"\"\n",
    "        self.convert_input(corpus, infer=False)\n",
    "        cmd = self.mallet_path + ' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\\\n",
    "            '--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\\\n",
    "            '--num-iterations %s --inferencer-filename %s --doc-topics-threshold %s  --random-seed %s'\n",
    "\n",
    "        cmd = cmd % (\n",
    "            self.fcorpusmallet(), self.num_topics, self.alpha, self.optimize_interval,\n",
    "            self.workers, self.fstate(), self.fdoctopics(), self.ftopickeys(), self.iterations,\n",
    "            self.finferencer(), self.topic_threshold, str(self.random_seed)\n",
    "        )\n",
    "        # NOTE \"--keep-sequence-bigrams\" / \"--use-ngrams true\" poorer results + runs out of memory\n",
    "        logger.info(\"training MALLET LDA with %s\", cmd)\n",
    "        check_output(args=cmd, shell=True)\n",
    "        self.word_topics = self.load_word_topics()\n",
    "        # NOTE - we are still keeping the wordtopics variable to not break backward compatibility.\n",
    "        # word_topics has replaced wordtopics throughout the code;\n",
    "        # wordtopics just stores the values of word_topics when train is called.\n",
    "        self.wordtopics = self.word_topics\n",
    "\n",
    "    def __getitem__(self, bow, iterations=100):\n",
    "        \"\"\"Get vector for document(s).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bow : {list of (int, int), iterable of list of (int, int)}\n",
    "            Document (or corpus) in BoW format.\n",
    "        iterations : int, optional\n",
    "            Number of iterations that will be used for inferring.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of (int, float)\n",
    "            LDA vector for document as sequence of (topic_id, topic_probability) **OR**\n",
    "        list of list of (int, float)\n",
    "            LDA vectors for corpus in same format.\n",
    "\n",
    "        \"\"\"\n",
    "        is_corpus, corpus = utils.is_corpus(bow)\n",
    "        if not is_corpus:\n",
    "            # query is a single document => make a corpus out of it\n",
    "            bow = [bow]\n",
    "\n",
    "        self.convert_input(bow, infer=True)\n",
    "        cmd = \\\n",
    "            self.mallet_path + ' infer-topics --input %s --inferencer %s ' \\\n",
    "                               '--output-doc-topics %s --num-iterations %s --doc-topics-threshold %s --random-seed %s'\n",
    "        cmd = cmd % (\n",
    "            self.fcorpusmallet() + '.infer', self.finferencer(),\n",
    "            self.fdoctopics() + '.infer', iterations, self.topic_threshold, str(self.random_seed)\n",
    "        )\n",
    "        logger.info(\"inferring topics with MALLET LDA '%s'\", cmd)\n",
    "        check_output(args=cmd, shell=True)\n",
    "        result = list(self.read_doctopics(self.fdoctopics() + '.infer'))\n",
    "        return result if is_corpus else result[0]\n",
    "\n",
    "    def load_word_topics(self):\n",
    "        \"\"\"Load words X topics matrix from :meth:`gensim.models.wrappers.ldamallet.LdaMallet.fstate` file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Matrix words X topics.\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info(\"loading assigned topics from %s\", self.fstate())\n",
    "        word_topics = numpy.zeros((self.num_topics, self.num_terms), dtype=numpy.float64)\n",
    "        if hasattr(self.id2word, 'token2id'):\n",
    "            word2id = self.id2word.token2id\n",
    "        else:\n",
    "            word2id = revdict(self.id2word)\n",
    "\n",
    "        with utils.open(self.fstate()) as fin:\n",
    "            _ = next(fin)  # header\n",
    "            self.alpha = numpy.fromiter(next(fin).split()[2:], dtype=float)\n",
    "            assert len(self.alpha) == self.num_topics, \"mismatch between MALLET vs. requested topics\"\n",
    "            _ = next(fin)  # noqa:F841 beta\n",
    "            for lineno, line in enumerate(fin):\n",
    "                line = utils.to_unicode(line)\n",
    "                doc, source, pos, typeindex, token, topic = line.split(\" \")\n",
    "                if token not in word2id:\n",
    "                    continue\n",
    "                tokenid = word2id[token]\n",
    "                word_topics[int(topic), tokenid] += 1.0\n",
    "        return word_topics\n",
    "\n",
    "    def load_document_topics(self):\n",
    "        \"\"\"Load document topics from :meth:`gensim.models.wrappers.ldamallet.LdaMallet.fdoctopics` file.\n",
    "        Shortcut for :meth:`gensim.models.wrappers.ldamallet.LdaMallet.read_doctopics`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        iterator of list of (int, float)\n",
    "            Sequence of LDA vectors for documents.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.read_doctopics(self.fdoctopics())\n",
    "\n",
    "    def get_topics(self):\n",
    "        \"\"\"Get topics X words matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Topics X words matrix, shape `num_topics` x `vocabulary_size`.\n",
    "\n",
    "        \"\"\"\n",
    "        topics = self.word_topics\n",
    "        return topics / topics.sum(axis=1)[:, None]\n",
    "\n",
    "    def show_topics(self, num_topics=10, num_words=10, log=False, formatted=True):\n",
    "        \"\"\"Get the `num_words` most probable words for `num_topics` number of topics.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_topics : int, optional\n",
    "            Number of topics to return, set `-1` to get all topics.\n",
    "        num_words : int, optional\n",
    "            Number of words.\n",
    "        log : bool, optional\n",
    "            If True - write topic with logging too, used for debug proposes.\n",
    "        formatted : bool, optional\n",
    "            If `True` - return the topics as a list of strings, otherwise as lists of (weight, word) pairs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of str\n",
    "            Topics as a list of strings (if formatted=True) **OR**\n",
    "        list of (float, str)\n",
    "            Topics as list of (weight, word) pairs (if formatted=False)\n",
    "\n",
    "        \"\"\"\n",
    "        if num_topics < 0 or num_topics >= self.num_topics:\n",
    "            num_topics = self.num_topics\n",
    "            chosen_topics = range(num_topics)\n",
    "        else:\n",
    "            num_topics = min(num_topics, self.num_topics)\n",
    "            # add a little random jitter, to randomize results around the same alpha\n",
    "            sort_alpha = self.alpha + 0.0001 * numpy.random.rand(len(self.alpha))\n",
    "            sorted_topics = list(matutils.argsort(sort_alpha))\n",
    "            chosen_topics = sorted_topics[: num_topics // 2] + sorted_topics[-num_topics // 2:]\n",
    "        shown = []\n",
    "        for i in chosen_topics:\n",
    "            if formatted:\n",
    "                topic = self.print_topic(i, topn=num_words)\n",
    "            else:\n",
    "                topic = self.show_topic(i, topn=num_words)\n",
    "            shown.append((i, topic))\n",
    "            if log:\n",
    "                logger.info(\"topic #%i (%.3f): %s\", i, self.alpha[i], topic)\n",
    "        return shown\n",
    "\n",
    "    def show_topic(self, topicid, topn=10, num_words=None):\n",
    "        \"\"\"Get `num_words` most probable words for the given `topicid`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        topicid : int\n",
    "            Id of topic.\n",
    "        topn : int, optional\n",
    "            Top number of topics that you'll receive.\n",
    "        num_words : int, optional\n",
    "            DEPRECATED PARAMETER, use `topn` instead.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of (str, float)\n",
    "            Sequence of probable words, as a list of `(word, word_probability)` for `topicid` topic.\n",
    "\n",
    "        \"\"\"\n",
    "        if num_words is not None:  # deprecated num_words is used\n",
    "            warnings.warn(\"The parameter `num_words` is deprecated, will be removed in 4.0.0, use `topn` instead.\")\n",
    "            topn = num_words\n",
    "\n",
    "        if self.word_topics is None:\n",
    "            logger.warning(\"Run train or load_word_topics before showing topics.\")\n",
    "        topic = self.word_topics[topicid]\n",
    "        topic = topic / topic.sum()  # normalize to probability dist\n",
    "        bestn = matutils.argsort(topic, topn, reverse=True)\n",
    "        beststr = [(self.id2word[idx], topic[idx]) for idx in bestn]\n",
    "        return beststr\n",
    "\n",
    "    def get_version(self, direc_path):\n",
    "        \"\"\"\"Get the version of Mallet.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        direc_path : str\n",
    "            Path to mallet archive.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Version of mallet.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            archive = zipfile.ZipFile(direc_path, 'r')\n",
    "            if u'cc/mallet/regression/' not in archive.namelist():\n",
    "                return '2.0.7'\n",
    "            else:\n",
    "                return '2.0.8RC3'\n",
    "        except Exception:\n",
    "\n",
    "            xml_path = direc_path.split(\"bin\")[0]\n",
    "            try:\n",
    "                doc = et.parse(xml_path + \"pom.xml\").getroot()\n",
    "                namespace = doc.tag[:doc.tag.index('}') + 1]\n",
    "                return doc.find(namespace + 'version').text.split(\"-\")[0]\n",
    "            except Exception:\n",
    "                return \"Can't parse pom.xml version file\"\n",
    "\n",
    "    def read_doctopics(self, fname, eps=1e-6, renorm=True):\n",
    "        \"\"\"Get document topic vectors from MALLET's \"doc-topics\" format, as sparse gensim vectors.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fname : str\n",
    "            Path to input file with document topics.\n",
    "        eps : float, optional\n",
    "            Threshold for probabilities.\n",
    "        renorm : bool, optional\n",
    "            If True - explicitly re-normalize distribution.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            If any line in invalid format.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        list of (int, float)\n",
    "            LDA vectors for document.\n",
    "\n",
    "        \"\"\"\n",
    "        mallet_version = self.get_version(self.mallet_path)\n",
    "        with utils.open(fname) as fin:\n",
    "            for lineno, line in enumerate(fin):\n",
    "                if lineno == 0 and line.startswith(b\"#doc \"):\n",
    "                    continue  # skip the header line if it exists\n",
    "\n",
    "                parts = line.split()[2:]  # skip \"doc\" and \"source\" columns\n",
    "\n",
    "                # the MALLET doctopic format changed in 2.0.8 to exclude the id,\n",
    "                # this handles the file differently dependent on the pattern\n",
    "                if len(parts) == 2 * self.num_topics:\n",
    "                    doc = [\n",
    "                        (int(id_), float(weight)) for id_, weight in zip(*[iter(parts)] * 2)\n",
    "                        if abs(float(weight)) > eps\n",
    "                    ]\n",
    "                elif len(parts) == self.num_topics and mallet_version != '2.0.7':\n",
    "                    doc = [(id_, float(weight)) for id_, weight in enumerate(parts) if abs(float(weight)) > eps]\n",
    "                else:\n",
    "                    if mallet_version == \"2.0.7\":\n",
    "                        \"\"\"\n",
    "\n",
    "                            1   1   0   1.0780612802674239  30.005575655428533364   2   0.005575655428533364\n",
    "                            2   2   0   0.9184413079632608  40.009062076892971008   3   0.009062076892971008\n",
    "                            In the above example there is a mix of the above if and elif statement.\n",
    "                            There are neither `2*num_topics` nor `num_topics` elements.\n",
    "                            It has 2 formats 40.009062076892971008 and 0   1.0780612802674239\n",
    "                            which cannot be handled by above if elif.\n",
    "                            Also, there are some topics are missing(meaning that the topic is not there)\n",
    "                            which is another reason why the above if elif fails even when the `mallet`\n",
    "                            produces the right results\n",
    "\n",
    "                        \"\"\"\n",
    "                        count = 0\n",
    "                        doc = []\n",
    "                        if len(parts) > 0:\n",
    "                            while count < len(parts):\n",
    "                                \"\"\"\n",
    "                                if section is to deal with formats of type 2 0.034\n",
    "                                so if count reaches index of 2 and since int(2) == float(2) so if block is executed\n",
    "                                now  there is one extra element afer 2, so count + 1 access should not give an error\n",
    "\n",
    "                                else section handles  formats of type 20.034\n",
    "                                now count is there on index of 20.034 since float(20.034) != int(20.034) so else block\n",
    "                                is executed\n",
    "\n",
    "                                \"\"\"\n",
    "                                if float(parts[count]) == int(parts[count]):\n",
    "                                    if float(parts[count + 1]) > eps:\n",
    "                                        doc.append((int(parts[count]), float(parts[count + 1])))\n",
    "                                    count += 2\n",
    "                                else:\n",
    "                                    if float(parts[count]) - int(parts[count]) > eps:\n",
    "                                        doc.append((int(parts[count]) % 10, float(parts[count]) - int(parts[count])))\n",
    "                                    count += 1\n",
    "                    else:\n",
    "                        raise RuntimeError(\"invalid doc topics format at line %i in %s\" % (lineno + 1, fname))\n",
    "\n",
    "                if renorm:\n",
    "                    # explicitly normalize weights to sum up to 1.0, just to be sure...\n",
    "                    total_weight = float(sum(weight for _, weight in doc))\n",
    "                    if total_weight:\n",
    "                        doc = [(id_, float(weight) / total_weight) for id_, weight in doc]\n",
    "                yield doc\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, *args, **kwargs):\n",
    "        \"\"\"Load a previously saved LdaMallet class. Handles backwards compatibility from\n",
    "        older LdaMallet versions which did not use random_seed parameter.\n",
    "        \"\"\"\n",
    "        model = super(LdaMallet, cls).load(*args, **kwargs)\n",
    "        if not hasattr(model, 'random_seed'):\n",
    "            model.random_seed = 0\n",
    "\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3804c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def malletmodel2ldamodel(mallet_model, gamma_threshold=0.001, iterations=50):\n",
    "    \"\"\"Convert :class:`~gensim.models.wrappers.ldamallet.LdaMallet` to :class:`~gensim.models.ldamodel.LdaModel`.\n",
    "\n",
    "    This works by copying the training model weights (alpha, beta...) from a trained mallet model into the gensim model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mallet_model : :class:`~gensim.models.wrappers.ldamallet.LdaMallet`\n",
    "        Trained Mallet model\n",
    "    gamma_threshold : float, optional\n",
    "        To be used for inference in the new LdaModel.\n",
    "    iterations : int, optional\n",
    "        Number of iterations to be used for inference in the new LdaModel.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    :class:`~gensim.models.ldamodel.LdaModel`\n",
    "        Gensim native LDA.\n",
    "\n",
    "    \"\"\"\n",
    "    model_gensim = LdaModel(\n",
    "        id2word=mallet_model.id2word, num_topics=mallet_model.num_topics,\n",
    "        alpha=mallet_model.alpha, eta=0,\n",
    "        iterations=iterations,\n",
    "        gamma_threshold=gamma_threshold,\n",
    "        dtype=numpy.float64  # don't loose precision when converting from MALLET\n",
    "    )\n",
    "    model_gensim.state.sstats[...] = mallet_model.wordtopics\n",
    "    model_gensim.sync_state()\n",
    "    return model_gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f629a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
